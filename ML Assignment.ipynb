{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95d9e6b2-ccba-4d9e-be2e-3b74f208e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (251, 47)\n",
      "Training labels shape: (251, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load training features\n",
    "X_train = pd.read_csv(\"traindata.txt\", header=None, sep=',')\n",
    "\n",
    "# Load training labels\n",
    "y_train = pd.read_csv(\"trainlabels.txt\", header=None, names=['label'])\n",
    "\n",
    "# Display shapes to verify\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04df00f8-16b9-4acb-b979-2d1ef0efceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.978522</td>\n",
       "      <td>0.168508</td>\n",
       "      <td>4.462580</td>\n",
       "      <td>3.090401</td>\n",
       "      <td>5.157773</td>\n",
       "      <td>0.032170</td>\n",
       "      <td>-260.015408</td>\n",
       "      <td>49696.695931</td>\n",
       "      <td>-3.140746</td>\n",
       "      <td>-0.166769</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.167519</td>\n",
       "      <td>0.810864</td>\n",
       "      <td>0.937615</td>\n",
       "      <td>-0.490792</td>\n",
       "      <td>-0.749121</td>\n",
       "      <td>1.147566</td>\n",
       "      <td>-0.715263</td>\n",
       "      <td>0.055411</td>\n",
       "      <td>-0.071415</td>\n",
       "      <td>molestias fuga ea repellendus voluptate perfer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.843618</td>\n",
       "      <td>1.755555</td>\n",
       "      <td>1.456022</td>\n",
       "      <td>1.174328</td>\n",
       "      <td>3.389254</td>\n",
       "      <td>-0.075575</td>\n",
       "      <td>-272.647889</td>\n",
       "      <td>42079.320285</td>\n",
       "      <td>1.300472</td>\n",
       "      <td>-3.149959</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.031475</td>\n",
       "      <td>0.668354</td>\n",
       "      <td>1.751136</td>\n",
       "      <td>-0.577402</td>\n",
       "      <td>0.412821</td>\n",
       "      <td>-1.192364</td>\n",
       "      <td>-0.928985</td>\n",
       "      <td>1.132198</td>\n",
       "      <td>0.365763</td>\n",
       "      <td>voluptate quam labore obcaecati eaque ullam ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.910161</td>\n",
       "      <td>2.653610</td>\n",
       "      <td>2.009792</td>\n",
       "      <td>7.012691</td>\n",
       "      <td>7.156772</td>\n",
       "      <td>0.157929</td>\n",
       "      <td>-61.689022</td>\n",
       "      <td>45257.340134</td>\n",
       "      <td>-2.083304</td>\n",
       "      <td>1.428207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833374</td>\n",
       "      <td>-0.361589</td>\n",
       "      <td>-1.117750</td>\n",
       "      <td>-0.358704</td>\n",
       "      <td>-0.840392</td>\n",
       "      <td>0.676442</td>\n",
       "      <td>0.080792</td>\n",
       "      <td>-0.681055</td>\n",
       "      <td>0.995872</td>\n",
       "      <td>cumque quidem reprehenderit fugit sint beatae ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114918</td>\n",
       "      <td>1.896752</td>\n",
       "      <td>2.355701</td>\n",
       "      <td>1.304806</td>\n",
       "      <td>1.291078</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>-330.317895</td>\n",
       "      <td>42094.046490</td>\n",
       "      <td>-3.117591</td>\n",
       "      <td>-0.219539</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.671187</td>\n",
       "      <td>2.090185</td>\n",
       "      <td>0.024688</td>\n",
       "      <td>-1.963173</td>\n",
       "      <td>1.197095</td>\n",
       "      <td>-0.751389</td>\n",
       "      <td>1.043713</td>\n",
       "      <td>0.121567</td>\n",
       "      <td>-1.570415</td>\n",
       "      <td>exercitationem sint accusamus ex ut neque opti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.143944</td>\n",
       "      <td>6.293296</td>\n",
       "      <td>12.358442</td>\n",
       "      <td>17.403780</td>\n",
       "      <td>21.024170</td>\n",
       "      <td>0.476258</td>\n",
       "      <td>89.555078</td>\n",
       "      <td>67771.456649</td>\n",
       "      <td>0.304133</td>\n",
       "      <td>-2.656630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285872</td>\n",
       "      <td>0.188486</td>\n",
       "      <td>0.551177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.411082</td>\n",
       "      <td>0.738194</td>\n",
       "      <td>-0.225395</td>\n",
       "      <td>-1.188597</td>\n",
       "      <td>1.443300</td>\n",
       "      <td>ad doloremque magni placeat officia tenetur as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1          2          3          4         5           6   \\\n",
       "0 -0.978522  0.168508   4.462580   3.090401   5.157773  0.032170 -260.015408   \n",
       "1  0.843618  1.755555   1.456022   1.174328   3.389254 -0.075575 -272.647889   \n",
       "2  5.910161  2.653610   2.009792   7.012691   7.156772  0.157929  -61.689022   \n",
       "3  0.114918  1.896752   2.355701   1.304806   1.291078  0.002818 -330.317895   \n",
       "4  6.143944  6.293296  12.358442  17.403780  21.024170  0.476258   89.555078   \n",
       "\n",
       "             7         8         9   ...        37        38        39  \\\n",
       "0  49696.695931 -3.140746 -0.166769  ... -1.167519  0.810864  0.937615   \n",
       "1  42079.320285  1.300472 -3.149959  ... -1.031475  0.668354  1.751136   \n",
       "2  45257.340134 -2.083304  1.428207  ... -0.833374 -0.361589 -1.117750   \n",
       "3  42094.046490 -3.117591 -0.219539  ... -1.671187  2.090185  0.024688   \n",
       "4  67771.456649  0.304133 -2.656630  ...  0.285872  0.188486  0.551177   \n",
       "\n",
       "         40        41        42        43        44        45  \\\n",
       "0 -0.490792 -0.749121  1.147566 -0.715263  0.055411 -0.071415   \n",
       "1 -0.577402  0.412821 -1.192364 -0.928985  1.132198  0.365763   \n",
       "2 -0.358704 -0.840392  0.676442  0.080792 -0.681055  0.995872   \n",
       "3 -1.963173  1.197095 -0.751389  1.043713  0.121567 -1.570415   \n",
       "4       NaN -0.411082  0.738194 -0.225395 -1.188597  1.443300   \n",
       "\n",
       "                                                  46  \n",
       "0  molestias fuga ea repellendus voluptate perfer...  \n",
       "1  voluptate quam labore obcaecati eaque ullam ma...  \n",
       "2  cumque quidem reprehenderit fugit sint beatae ...  \n",
       "3  exercitationem sint accusamus ex ut neque opti...  \n",
       "4  ad doloremque magni placeat officia tenetur as...  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14cc6a33-8486-4ab4-8c52-01566c187175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      0\n",
       "1      0\n",
       "2      2\n",
       "3      0\n",
       "4      7"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b28638c-56a4-4bf4-b748-7a1158f4dd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.978522</td>\n",
       "      <td>0.168508</td>\n",
       "      <td>4.462580</td>\n",
       "      <td>3.090401</td>\n",
       "      <td>5.157773</td>\n",
       "      <td>0.032170</td>\n",
       "      <td>-260.015408</td>\n",
       "      <td>49696.695931</td>\n",
       "      <td>-3.140746</td>\n",
       "      <td>-0.166769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810864</td>\n",
       "      <td>0.937615</td>\n",
       "      <td>-0.490792</td>\n",
       "      <td>-0.749121</td>\n",
       "      <td>1.147566</td>\n",
       "      <td>-0.715263</td>\n",
       "      <td>0.055411</td>\n",
       "      <td>-0.071415</td>\n",
       "      <td>molestias fuga ea repellendus voluptate perfer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.843618</td>\n",
       "      <td>1.755555</td>\n",
       "      <td>1.456022</td>\n",
       "      <td>1.174328</td>\n",
       "      <td>3.389254</td>\n",
       "      <td>-0.075575</td>\n",
       "      <td>-272.647889</td>\n",
       "      <td>42079.320285</td>\n",
       "      <td>1.300472</td>\n",
       "      <td>-3.149959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668354</td>\n",
       "      <td>1.751136</td>\n",
       "      <td>-0.577402</td>\n",
       "      <td>0.412821</td>\n",
       "      <td>-1.192364</td>\n",
       "      <td>-0.928985</td>\n",
       "      <td>1.132198</td>\n",
       "      <td>0.365763</td>\n",
       "      <td>voluptate quam labore obcaecati eaque ullam ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.910161</td>\n",
       "      <td>2.653610</td>\n",
       "      <td>2.009792</td>\n",
       "      <td>7.012691</td>\n",
       "      <td>7.156772</td>\n",
       "      <td>0.157929</td>\n",
       "      <td>-61.689022</td>\n",
       "      <td>45257.340134</td>\n",
       "      <td>-2.083304</td>\n",
       "      <td>1.428207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361589</td>\n",
       "      <td>-1.117750</td>\n",
       "      <td>-0.358704</td>\n",
       "      <td>-0.840392</td>\n",
       "      <td>0.676442</td>\n",
       "      <td>0.080792</td>\n",
       "      <td>-0.681055</td>\n",
       "      <td>0.995872</td>\n",
       "      <td>cumque quidem reprehenderit fugit sint beatae ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114918</td>\n",
       "      <td>1.896752</td>\n",
       "      <td>2.355701</td>\n",
       "      <td>1.304806</td>\n",
       "      <td>1.291078</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>-330.317895</td>\n",
       "      <td>42094.046490</td>\n",
       "      <td>-3.117591</td>\n",
       "      <td>-0.219539</td>\n",
       "      <td>...</td>\n",
       "      <td>2.090185</td>\n",
       "      <td>0.024688</td>\n",
       "      <td>-1.963173</td>\n",
       "      <td>1.197095</td>\n",
       "      <td>-0.751389</td>\n",
       "      <td>1.043713</td>\n",
       "      <td>0.121567</td>\n",
       "      <td>-1.570415</td>\n",
       "      <td>exercitationem sint accusamus ex ut neque opti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.143944</td>\n",
       "      <td>6.293296</td>\n",
       "      <td>12.358442</td>\n",
       "      <td>17.403780</td>\n",
       "      <td>21.024170</td>\n",
       "      <td>0.476258</td>\n",
       "      <td>89.555078</td>\n",
       "      <td>67771.456649</td>\n",
       "      <td>0.304133</td>\n",
       "      <td>-2.656630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188486</td>\n",
       "      <td>0.551177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.411082</td>\n",
       "      <td>0.738194</td>\n",
       "      <td>-0.225395</td>\n",
       "      <td>-1.188597</td>\n",
       "      <td>1.443300</td>\n",
       "      <td>ad doloremque magni placeat officia tenetur as...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1          2          3          4         5           6  \\\n",
       "0 -0.978522  0.168508   4.462580   3.090401   5.157773  0.032170 -260.015408   \n",
       "1  0.843618  1.755555   1.456022   1.174328   3.389254 -0.075575 -272.647889   \n",
       "2  5.910161  2.653610   2.009792   7.012691   7.156772  0.157929  -61.689022   \n",
       "3  0.114918  1.896752   2.355701   1.304806   1.291078  0.002818 -330.317895   \n",
       "4  6.143944  6.293296  12.358442  17.403780  21.024170  0.476258   89.555078   \n",
       "\n",
       "              7         8         9  ...        38        39        40  \\\n",
       "0  49696.695931 -3.140746 -0.166769  ...  0.810864  0.937615 -0.490792   \n",
       "1  42079.320285  1.300472 -3.149959  ...  0.668354  1.751136 -0.577402   \n",
       "2  45257.340134 -2.083304  1.428207  ... -0.361589 -1.117750 -0.358704   \n",
       "3  42094.046490 -3.117591 -0.219539  ...  2.090185  0.024688 -1.963173   \n",
       "4  67771.456649  0.304133 -2.656630  ...  0.188486  0.551177       NaN   \n",
       "\n",
       "         41        42        43        44        45  \\\n",
       "0 -0.749121  1.147566 -0.715263  0.055411 -0.071415   \n",
       "1  0.412821 -1.192364 -0.928985  1.132198  0.365763   \n",
       "2 -0.840392  0.676442  0.080792 -0.681055  0.995872   \n",
       "3  1.197095 -0.751389  1.043713  0.121567 -1.570415   \n",
       "4 -0.411082  0.738194 -0.225395 -1.188597  1.443300   \n",
       "\n",
       "                                                  46  label  \n",
       "0  molestias fuga ea repellendus voluptate perfer...      0  \n",
       "1  voluptate quam labore obcaecati eaque ullam ma...      0  \n",
       "2  cumque quidem reprehenderit fugit sint beatae ...      2  \n",
       "3  exercitationem sint accusamus ex ut neque opti...      0  \n",
       "4  ad doloremque magni placeat officia tenetur as...      7  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining training data and training labels to make it easy to clean\n",
    "df = X_train.copy()\n",
    "df[\"label\"] = y_train.values.ravel() \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0313370-9967-44ac-81b4-326d64e8de3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        float64\n",
      "1        float64\n",
      "2        float64\n",
      "3        float64\n",
      "4        float64\n",
      "5        float64\n",
      "6        float64\n",
      "7        float64\n",
      "8        float64\n",
      "9        float64\n",
      "10       float64\n",
      "11       float64\n",
      "12       float64\n",
      "13       float64\n",
      "14       float64\n",
      "15       float64\n",
      "16       float64\n",
      "17       float64\n",
      "18       float64\n",
      "19       float64\n",
      "20       float64\n",
      "21       float64\n",
      "22       float64\n",
      "23       float64\n",
      "24       float64\n",
      "25       float64\n",
      "26       float64\n",
      "27       float64\n",
      "28       float64\n",
      "29       float64\n",
      "30       float64\n",
      "31       float64\n",
      "32       float64\n",
      "33       float64\n",
      "34       float64\n",
      "35       float64\n",
      "36       float64\n",
      "37       float64\n",
      "38       float64\n",
      "39       float64\n",
      "40       float64\n",
      "41       float64\n",
      "42       float64\n",
      "43       float64\n",
      "44       float64\n",
      "45       float64\n",
      "46        object\n",
      "label      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87b1cf23-21a7-46cb-9fb3-caf03c26f76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        5\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "5        5\n",
       "6        5\n",
       "7        5\n",
       "8        5\n",
       "9        0\n",
       "10       0\n",
       "11       0\n",
       "12       0\n",
       "13       0\n",
       "14       5\n",
       "15       5\n",
       "16       0\n",
       "17       5\n",
       "18       0\n",
       "19       0\n",
       "20       0\n",
       "21       0\n",
       "22       0\n",
       "23       0\n",
       "24       0\n",
       "25       0\n",
       "26       0\n",
       "27       5\n",
       "28       0\n",
       "29       0\n",
       "30       0\n",
       "31       0\n",
       "32       0\n",
       "33       0\n",
       "34       5\n",
       "35       0\n",
       "36       0\n",
       "37       0\n",
       "38       0\n",
       "39       0\n",
       "40       5\n",
       "41       0\n",
       "42       0\n",
       "43       0\n",
       "44       0\n",
       "45       0\n",
       "46       0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if we have missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4b54d2b-f814-4b41-a11d-9c53903505a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df[1].hist(bins=30)\n",
    "plt.title(\"Distribution of Column 1\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4654a37-5d3a-47a6-8eec-6b065650ec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "5        0\n",
      "6        0\n",
      "7        0\n",
      "8        0\n",
      "9        0\n",
      "10       0\n",
      "11       0\n",
      "12       0\n",
      "13       0\n",
      "14       0\n",
      "15       0\n",
      "16       0\n",
      "17       0\n",
      "18       0\n",
      "19       0\n",
      "20       0\n",
      "21       0\n",
      "22       0\n",
      "23       0\n",
      "24       0\n",
      "25       0\n",
      "26       0\n",
      "27       0\n",
      "28       0\n",
      "29       0\n",
      "30       0\n",
      "31       0\n",
      "32       0\n",
      "33       0\n",
      "34       0\n",
      "35       0\n",
      "36       0\n",
      "37       0\n",
      "38       0\n",
      "39       0\n",
      "40       0\n",
      "41       0\n",
      "42       0\n",
      "43       0\n",
      "44       0\n",
      "45       0\n",
      "46       0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#dropping missing values\n",
    "columns_with_missing = [1, 5, 6, 7, 8, 14, 15, 17, 27, 34, 40]\n",
    "\n",
    "for col in columns_with_missing:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "252eff77-df7b-46e3-9ff0-d3c0bf4d0e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 7 6 1 3 8 5 4 9]\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32ac1a9f-be3e-4d10-984c-20c4f69f2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.iloc[:, 46].astype(str)   # Column with random words\n",
    "labels = df.iloc[:, 47].astype(int)  # Labels from 0 to 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "495ed4ff-9aa2-433e-91e5-980ab259e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # Limit for speed\n",
    "X_text = vectorizer.fit_transform(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbe4a11a-9746-4099-9d79-7efdf8810124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\busis\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score using ONLY text column: 0.06398699723547088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "scores = cross_val_score(clf, X_text, labels, scoring='f1_macro', cv=5)\n",
    "\n",
    "print(\"F1 score using ONLY text column:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02529de0-7547-4802-b13c-9a3d357bdeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##drop 46 as it has not much predictive power on label\n",
    "df = df.drop(columns=df.columns[46])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aab512f2-7bb7-4bc9-a6d1-588d745714cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.978522</td>\n",
       "      <td>0.168508</td>\n",
       "      <td>4.462580</td>\n",
       "      <td>3.090401</td>\n",
       "      <td>5.157773</td>\n",
       "      <td>0.032170</td>\n",
       "      <td>-260.015408</td>\n",
       "      <td>49696.695931</td>\n",
       "      <td>-3.140746</td>\n",
       "      <td>-0.166769</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.167519</td>\n",
       "      <td>0.810864</td>\n",
       "      <td>0.937615</td>\n",
       "      <td>-0.490792</td>\n",
       "      <td>-0.749121</td>\n",
       "      <td>1.147566</td>\n",
       "      <td>-0.715263</td>\n",
       "      <td>0.055411</td>\n",
       "      <td>-0.071415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.843618</td>\n",
       "      <td>1.755555</td>\n",
       "      <td>1.456022</td>\n",
       "      <td>1.174328</td>\n",
       "      <td>3.389254</td>\n",
       "      <td>-0.075575</td>\n",
       "      <td>-272.647889</td>\n",
       "      <td>42079.320285</td>\n",
       "      <td>1.300472</td>\n",
       "      <td>-3.149959</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.031475</td>\n",
       "      <td>0.668354</td>\n",
       "      <td>1.751136</td>\n",
       "      <td>-0.577402</td>\n",
       "      <td>0.412821</td>\n",
       "      <td>-1.192364</td>\n",
       "      <td>-0.928985</td>\n",
       "      <td>1.132198</td>\n",
       "      <td>0.365763</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.910161</td>\n",
       "      <td>2.653610</td>\n",
       "      <td>2.009792</td>\n",
       "      <td>7.012691</td>\n",
       "      <td>7.156772</td>\n",
       "      <td>0.157929</td>\n",
       "      <td>-61.689022</td>\n",
       "      <td>45257.340134</td>\n",
       "      <td>-2.083304</td>\n",
       "      <td>1.428207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833374</td>\n",
       "      <td>-0.361589</td>\n",
       "      <td>-1.117750</td>\n",
       "      <td>-0.358704</td>\n",
       "      <td>-0.840392</td>\n",
       "      <td>0.676442</td>\n",
       "      <td>0.080792</td>\n",
       "      <td>-0.681055</td>\n",
       "      <td>0.995872</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114918</td>\n",
       "      <td>1.896752</td>\n",
       "      <td>2.355701</td>\n",
       "      <td>1.304806</td>\n",
       "      <td>1.291078</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>-330.317895</td>\n",
       "      <td>42094.046490</td>\n",
       "      <td>-3.117591</td>\n",
       "      <td>-0.219539</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.671187</td>\n",
       "      <td>2.090185</td>\n",
       "      <td>0.024688</td>\n",
       "      <td>-1.963173</td>\n",
       "      <td>1.197095</td>\n",
       "      <td>-0.751389</td>\n",
       "      <td>1.043713</td>\n",
       "      <td>0.121567</td>\n",
       "      <td>-1.570415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.143944</td>\n",
       "      <td>6.293296</td>\n",
       "      <td>12.358442</td>\n",
       "      <td>17.403780</td>\n",
       "      <td>21.024170</td>\n",
       "      <td>0.476258</td>\n",
       "      <td>89.555078</td>\n",
       "      <td>67771.456649</td>\n",
       "      <td>0.304133</td>\n",
       "      <td>-2.656630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285872</td>\n",
       "      <td>0.188486</td>\n",
       "      <td>0.551177</td>\n",
       "      <td>-0.210898</td>\n",
       "      <td>-0.411082</td>\n",
       "      <td>0.738194</td>\n",
       "      <td>-0.225395</td>\n",
       "      <td>-1.188597</td>\n",
       "      <td>1.443300</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1          2          3          4         5           6  \\\n",
       "0 -0.978522  0.168508   4.462580   3.090401   5.157773  0.032170 -260.015408   \n",
       "1  0.843618  1.755555   1.456022   1.174328   3.389254 -0.075575 -272.647889   \n",
       "2  5.910161  2.653610   2.009792   7.012691   7.156772  0.157929  -61.689022   \n",
       "3  0.114918  1.896752   2.355701   1.304806   1.291078  0.002818 -330.317895   \n",
       "4  6.143944  6.293296  12.358442  17.403780  21.024170  0.476258   89.555078   \n",
       "\n",
       "              7         8         9  ...        37        38        39  \\\n",
       "0  49696.695931 -3.140746 -0.166769  ... -1.167519  0.810864  0.937615   \n",
       "1  42079.320285  1.300472 -3.149959  ... -1.031475  0.668354  1.751136   \n",
       "2  45257.340134 -2.083304  1.428207  ... -0.833374 -0.361589 -1.117750   \n",
       "3  42094.046490 -3.117591 -0.219539  ... -1.671187  2.090185  0.024688   \n",
       "4  67771.456649  0.304133 -2.656630  ...  0.285872  0.188486  0.551177   \n",
       "\n",
       "         40        41        42        43        44        45  label  \n",
       "0 -0.490792 -0.749121  1.147566 -0.715263  0.055411 -0.071415      0  \n",
       "1 -0.577402  0.412821 -1.192364 -0.928985  1.132198  0.365763      0  \n",
       "2 -0.358704 -0.840392  0.676442  0.080792 -0.681055  0.995872      2  \n",
       "3 -1.963173  1.197095 -0.751389  1.043713  0.121567 -1.570415      0  \n",
       "4 -0.210898 -0.411082  0.738194 -0.225395 -1.188597  1.443300      7  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "002bde95-a090-4a88-8d7c-7f9df2d6d215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>0</th>\n",
       "      <th>8</th>\n",
       "      <th>27</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>9</th>\n",
       "      <th>39</th>\n",
       "      <th>10</th>\n",
       "      <th>30</th>\n",
       "      <th>14</th>\n",
       "      <th>24</th>\n",
       "      <th>43</th>\n",
       "      <th>28</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.157773</td>\n",
       "      <td>3.090401</td>\n",
       "      <td>0.168508</td>\n",
       "      <td>4.462580</td>\n",
       "      <td>0.032170</td>\n",
       "      <td>-260.015408</td>\n",
       "      <td>49696.695931</td>\n",
       "      <td>-0.978522</td>\n",
       "      <td>-3.140746</td>\n",
       "      <td>0.901685</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.024950</td>\n",
       "      <td>-0.166769</td>\n",
       "      <td>0.937615</td>\n",
       "      <td>-1.219136</td>\n",
       "      <td>1.319422</td>\n",
       "      <td>-9.504768</td>\n",
       "      <td>0.635253</td>\n",
       "      <td>-0.715263</td>\n",
       "      <td>-0.381271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.389254</td>\n",
       "      <td>1.174328</td>\n",
       "      <td>1.755555</td>\n",
       "      <td>1.456022</td>\n",
       "      <td>-0.075575</td>\n",
       "      <td>-272.647889</td>\n",
       "      <td>42079.320285</td>\n",
       "      <td>0.843618</td>\n",
       "      <td>1.300472</td>\n",
       "      <td>-0.170776</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.189224</td>\n",
       "      <td>-3.149959</td>\n",
       "      <td>1.751136</td>\n",
       "      <td>1.519093</td>\n",
       "      <td>-0.282997</td>\n",
       "      <td>-7.972720</td>\n",
       "      <td>0.069150</td>\n",
       "      <td>-0.928985</td>\n",
       "      <td>-0.893654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.156772</td>\n",
       "      <td>7.012691</td>\n",
       "      <td>2.653610</td>\n",
       "      <td>2.009792</td>\n",
       "      <td>0.157929</td>\n",
       "      <td>-61.689022</td>\n",
       "      <td>45257.340134</td>\n",
       "      <td>5.910161</td>\n",
       "      <td>-2.083304</td>\n",
       "      <td>1.583477</td>\n",
       "      <td>...</td>\n",
       "      <td>1.490379</td>\n",
       "      <td>1.428207</td>\n",
       "      <td>-1.117750</td>\n",
       "      <td>-3.230733</td>\n",
       "      <td>-0.779296</td>\n",
       "      <td>-9.560659</td>\n",
       "      <td>-0.239377</td>\n",
       "      <td>0.080792</td>\n",
       "      <td>-1.117779</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.291078</td>\n",
       "      <td>1.304806</td>\n",
       "      <td>1.896752</td>\n",
       "      <td>2.355701</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>-330.317895</td>\n",
       "      <td>42094.046490</td>\n",
       "      <td>0.114918</td>\n",
       "      <td>-3.117591</td>\n",
       "      <td>-0.655406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419989</td>\n",
       "      <td>-0.219539</td>\n",
       "      <td>0.024688</td>\n",
       "      <td>1.289256</td>\n",
       "      <td>0.368103</td>\n",
       "      <td>5.079488</td>\n",
       "      <td>-0.333315</td>\n",
       "      <td>1.043713</td>\n",
       "      <td>0.190633</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.024170</td>\n",
       "      <td>17.403780</td>\n",
       "      <td>6.293296</td>\n",
       "      <td>12.358442</td>\n",
       "      <td>0.476258</td>\n",
       "      <td>89.555078</td>\n",
       "      <td>67771.456649</td>\n",
       "      <td>6.143944</td>\n",
       "      <td>0.304133</td>\n",
       "      <td>0.128451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684719</td>\n",
       "      <td>-2.656630</td>\n",
       "      <td>0.551177</td>\n",
       "      <td>-0.313484</td>\n",
       "      <td>-0.783585</td>\n",
       "      <td>6.801789</td>\n",
       "      <td>-1.507209</td>\n",
       "      <td>-0.225395</td>\n",
       "      <td>-0.591305</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           4          3         1          2         5           6  \\\n",
       "0   5.157773   3.090401  0.168508   4.462580  0.032170 -260.015408   \n",
       "1   3.389254   1.174328  1.755555   1.456022 -0.075575 -272.647889   \n",
       "2   7.156772   7.012691  2.653610   2.009792  0.157929  -61.689022   \n",
       "3   1.291078   1.304806  1.896752   2.355701  0.002818 -330.317895   \n",
       "4  21.024170  17.403780  6.293296  12.358442  0.476258   89.555078   \n",
       "\n",
       "              7         0         8        27  ...        36         9  \\\n",
       "0  49696.695931 -0.978522 -3.140746  0.901685  ... -1.024950 -0.166769   \n",
       "1  42079.320285  0.843618  1.300472 -0.170776  ... -1.189224 -3.149959   \n",
       "2  45257.340134  5.910161 -2.083304  1.583477  ...  1.490379  1.428207   \n",
       "3  42094.046490  0.114918 -3.117591 -0.655406  ...  0.419989 -0.219539   \n",
       "4  67771.456649  6.143944  0.304133  0.128451  ...  0.684719 -2.656630   \n",
       "\n",
       "         39        10        30        14        24        43        28  label  \n",
       "0  0.937615 -1.219136  1.319422 -9.504768  0.635253 -0.715263 -0.381271      0  \n",
       "1  1.751136  1.519093 -0.282997 -7.972720  0.069150 -0.928985 -0.893654      0  \n",
       "2 -1.117750 -3.230733 -0.779296 -9.560659 -0.239377  0.080792 -1.117779      2  \n",
       "3  0.024688  1.289256  0.368103  5.079488 -0.333315  1.043713  0.190633      0  \n",
       "4  0.551177 -0.313484 -0.783585  6.801789 -1.507209 -0.225395 -0.591305      7  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##feature selection based on correlations, dropping features that have low correlation and keepting top 20\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1].astype(int) \n",
    "\n",
    "\n",
    "correlations = features.corrwith(labels).abs().sort_values(ascending=False)\n",
    "top_n = 20\n",
    "top_features = correlations.head(top_n).index\n",
    "\n",
    "\n",
    "X_selected = features[top_features]\n",
    "\n",
    "\n",
    "df_selected = pd.concat([X_selected, labels], axis=1)\n",
    "\n",
    "\n",
    "df_selected.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26617de0-5e4b-4d4f-8da2-de18b8c830f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 47)\n",
      "(251, 21)\n"
     ]
    }
   ],
   "source": [
    "#new preprocessed datset must have same number of rows as old dataset but less columns due to feature selection\n",
    "print(df.shape)\n",
    "print(df_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca8c7e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (200, 46), Testing: (51, 46)\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(df):\n",
    "    split_idx = int(len(df) * 0.8)\n",
    "    \n",
    "    # Training data\n",
    "    train_data = df.iloc[:split_idx, :-1].values\n",
    "    train_labels = df.iloc[:split_idx, -1].values\n",
    "    \n",
    "    # Test data  \n",
    "    test_data = df.iloc[split_idx:, :-1].values\n",
    "    test_labels = df.iloc[split_idx:, -1].values\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = prepare_data(df)\n",
    "print(f\"Training: {train_data.shape}, Testing: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccaeb526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in train_labels: [0 1 2 3 4 5 6 7 8 9]\n",
      "Min label: 0\n",
      "Max label: 9\n",
      "Number of unique labels: 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# First, let's see what labels exist in your data\n",
    "print(\"Unique labels in train_labels:\", np.unique(train_labels))\n",
    "print(\"Min label:\", np.min(train_labels))\n",
    "print(\"Max label:\", np.max(train_labels))\n",
    "\n",
    "# Count how many unique labels you have\n",
    "n_unique_labels = len(np.unique(train_labels))\n",
    "print(f\"Number of unique labels: {n_unique_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a3702a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.245, 0.175, 0.15 , 0.125, 0.1  , 0.065, 0.04 , 0.055, 0.03 ,\n",
       "       0.015])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "priors = np.zeros(10)\n",
    "unique_labels, counts = np.unique(train_labels, return_counts=True)\n",
    "total_samples = len(train_labels)\n",
    "\n",
    "for i, (label, count) in enumerate(zip(unique_labels, counts)):\n",
    "    priors[int(label)] = count / total_samples\n",
    "\n",
    "priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d4ed63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.10168408e-01,  9.05466083e-01,  4.75759336e+00,\n",
       "         2.04505420e+00,  2.59839816e+00,  6.29046619e+00,\n",
       "         3.42684234e+00,  3.92015871e+00,  4.64223323e+00,\n",
       "         5.30318400e+00],\n",
       "       [ 1.00530639e+00,  1.98299472e+00,  3.07319456e+00,\n",
       "         4.16648200e+00,  4.81290399e+00,  6.02923386e+00,\n",
       "         7.17067799e+00,  7.70492984e+00,  9.01010668e+00,\n",
       "         1.05811178e+01],\n",
       "       [ 2.45571881e+00,  2.91947776e+00,  4.41169079e+00,\n",
       "         7.23241878e+00,  7.47980857e+00,  9.01696733e+00,\n",
       "         1.27205553e+01,  1.21912382e+01,  1.31821702e+01,\n",
       "         1.49513057e+01],\n",
       "       [ 2.27706249e+00,  4.20592549e+00,  6.78609694e+00,\n",
       "         8.28147626e+00,  9.87796504e+00,  1.23782083e+01,\n",
       "         1.23355686e+01,  1.57966739e+01,  1.83085901e+01,\n",
       "         2.01799079e+01],\n",
       "       [ 2.85012328e+00,  4.81368385e+00,  8.09013088e+00,\n",
       "         1.02869701e+01,  1.20311650e+01,  1.54005790e+01,\n",
       "         1.77203832e+01,  2.08973774e+01,  2.16146821e+01,\n",
       "         2.47647940e+01],\n",
       "       [ 2.04350130e-02,  4.26091056e-02,  1.20528010e-01,\n",
       "         1.73474849e-01,  2.17960699e-01,  2.73672686e-01,\n",
       "         3.29545712e-01,  3.40382159e-01,  4.85227244e-01,\n",
       "         4.29107096e-01],\n",
       "       [-2.62083775e+02, -2.20707618e+02, -1.28867676e+02,\n",
       "        -7.80618863e+01, -3.77041916e+01,  6.84133167e+00,\n",
       "         2.67511392e+01,  9.77670301e+01,  1.33538154e+02,\n",
       "         2.58247088e+02],\n",
       "       [ 4.93150110e+04,  5.16245628e+04,  5.37138135e+04,\n",
       "         5.55609313e+04,  5.86287378e+04,  6.06963577e+04,\n",
       "         6.15841928e+04,  6.69174168e+04,  6.36432933e+04,\n",
       "         6.69956843e+04],\n",
       "       [-2.58806712e-01,  3.99269934e-01, -1.75847755e-01,\n",
       "        -1.06515646e-01,  7.77346873e-01,  4.82750674e-01,\n",
       "         3.30569600e-01,  1.65696150e+00,  2.96540949e+00,\n",
       "         7.79722235e-01],\n",
       "       [-4.99998338e-01, -8.99082223e-02,  3.30591349e-01,\n",
       "         7.38967846e-01, -2.47732610e-01,  2.22637252e-01,\n",
       "        -5.36806728e-01,  7.34273400e-01,  8.26857617e-01,\n",
       "         3.95023435e-02],\n",
       "       [ 2.86593306e-02, -2.29566577e-01, -3.27569747e-01,\n",
       "        -1.00838993e-02,  8.00887853e-01, -1.13798098e+00,\n",
       "         3.76029354e-01,  1.01432752e+00,  3.35519982e-01,\n",
       "         1.11375731e+00],\n",
       "       [-6.90564623e-01,  5.25325517e-02,  2.43986529e-01,\n",
       "        -5.17758407e-02,  5.19970449e-01, -6.21826122e-01,\n",
       "        -1.56148051e+00,  7.50013676e-01, -8.10167797e-01,\n",
       "        -1.66456682e+00],\n",
       "       [-3.32371039e+00, -1.62914088e+00, -2.47002332e+00,\n",
       "        -3.48061117e+00, -3.06689061e+00, -2.00090461e+00,\n",
       "        -8.04080534e-01, -3.80357379e+00, -1.09001696e+00,\n",
       "        -5.27841529e+00],\n",
       "       [ 1.94723917e+00,  2.76848284e+00,  5.86695542e-01,\n",
       "         1.01837989e+00, -5.02539942e-02,  3.81516521e+00,\n",
       "         7.76575730e+00,  6.48291454e-01,  1.11378440e+00,\n",
       "         4.01681161e+00],\n",
       "       [-3.68002656e+00, -5.90527845e+00, -6.34987120e+00,\n",
       "        -4.65496760e+00, -5.35376495e+00, -3.38380475e+00,\n",
       "         4.17918238e-02, -3.75433101e+00, -6.11557140e+00,\n",
       "         8.10197656e-01],\n",
       "       [ 5.62181954e+00,  6.69717721e+00,  7.21810267e+00,\n",
       "         6.30080003e+00,  5.67393257e+00,  4.76861147e+00,\n",
       "         5.70484025e+00,  5.58224512e+00,  8.25440626e+00,\n",
       "         5.47407110e+00],\n",
       "       [-6.63957557e-03,  8.37085460e-03,  1.70462270e-01,\n",
       "         2.49033310e-01, -2.18241005e-01,  4.82409970e-02,\n",
       "         8.93472006e-02,  9.67097830e-02, -4.84014388e-01,\n",
       "        -7.54450728e-01],\n",
       "       [-1.10429783e-01, -7.82630176e-02,  1.26626893e-01,\n",
       "         2.95406768e-01,  3.55065152e-03, -1.78354144e-01,\n",
       "        -2.91279658e-01,  1.52768576e-01,  1.43855325e-01,\n",
       "        -1.86905212e-01],\n",
       "       [-1.93750628e-01, -3.97524204e-01,  2.99541322e-02,\n",
       "        -1.79017445e-01, -1.37951227e-01, -2.21233914e-01,\n",
       "         3.49630773e-01,  2.56083605e-01,  3.80696764e-01,\n",
       "        -9.97173879e-02],\n",
       "       [-1.13302384e-02,  1.01334298e-01,  1.29858302e-02,\n",
       "        -2.89099415e-01,  1.75886720e-02,  1.25199510e-01,\n",
       "        -3.76530459e-02, -3.90695644e-02,  4.27251763e-01,\n",
       "         6.88353735e-02],\n",
       "       [ 1.45954476e-01, -6.97257184e-02,  4.59496534e-02,\n",
       "         2.59179620e-02,  8.21772756e-02,  7.84150539e-02,\n",
       "        -1.70387956e-01, -1.55372500e-01,  4.22747274e-01,\n",
       "         3.22003404e-01],\n",
       "       [ 4.09099090e-02, -3.94684312e-02,  1.53820435e-01,\n",
       "        -1.73521883e-01, -4.01957843e-02, -1.76334868e-01,\n",
       "         6.48400094e-01, -1.28542658e-01,  2.34902073e-01,\n",
       "         3.38024018e-01],\n",
       "       [ 1.17491547e-01,  8.56001396e-02, -1.67685167e-02,\n",
       "         1.65368091e-01, -4.04698565e-02, -2.05397699e-01,\n",
       "         1.14054356e-01,  1.13234041e-01,  1.59311033e-01,\n",
       "        -2.65043582e-01],\n",
       "       [ 4.74009074e-02,  5.80445924e-02,  2.20321934e-01,\n",
       "        -2.53320077e-01, -2.13089051e-01, -3.43476099e-01,\n",
       "         3.76655787e-01, -2.97304700e-01, -4.52312481e-02,\n",
       "        -2.65604848e-01],\n",
       "       [ 8.21989079e-02, -2.09879688e-01, -2.27466465e-01,\n",
       "         2.57721052e-01,  2.33444973e-01, -9.02310341e-02,\n",
       "         6.17547934e-01, -2.17305927e-01,  1.22076750e-01,\n",
       "         3.87460386e-01],\n",
       "       [ 1.87165553e-01, -7.03281950e-02, -1.69906186e-01,\n",
       "        -2.04999852e-01,  4.81979202e-02,  5.11591810e-01,\n",
       "        -5.13494821e-01,  1.40443443e-01, -2.46776493e-01,\n",
       "         4.86868953e-01],\n",
       "       [ 1.42678684e-01, -6.99211610e-02, -1.61236391e-01,\n",
       "        -5.15497101e-01, -2.85379405e-01, -2.20473722e-01,\n",
       "         4.10443434e-01,  4.31815036e-01,  2.78669079e-01,\n",
       "        -5.76836409e-01],\n",
       "       [-1.71504331e-01, -4.69714691e-01, -2.94950316e-01,\n",
       "         9.12760319e-02,  3.25694248e-01,  1.45569065e-02,\n",
       "         3.53373982e-01,  1.49750578e-03,  7.65549380e-02,\n",
       "         1.00728201e+00],\n",
       "       [-1.29659417e-01,  5.98556427e-02, -1.40000025e-01,\n",
       "         3.63306494e-02,  2.34157711e-01,  4.25131655e-01,\n",
       "        -6.81949572e-01,  2.24178939e-01, -1.16125452e-01,\n",
       "         5.24912147e-01],\n",
       "       [-7.77996970e-02,  2.99479908e-02,  1.47549936e-01,\n",
       "         7.62774516e-02,  1.04056928e-01,  4.52243196e-01,\n",
       "        -8.25555631e-02, -2.53779999e-01,  6.27517504e-01,\n",
       "         4.66406122e-01],\n",
       "       [-4.13288338e-02, -2.75614730e-01, -6.84308376e-02,\n",
       "         3.96215597e-02,  7.94996030e-02,  2.38677369e-01,\n",
       "         9.52657296e-02,  2.56617440e-01, -8.71636299e-01,\n",
       "         3.57610992e-01],\n",
       "       [ 1.10279856e-01,  9.67237135e-02,  2.05837261e-02,\n",
       "        -1.52506586e-01,  1.52395181e-01,  5.22957932e-01,\n",
       "        -2.27483887e-01, -1.49371667e-01,  9.13882700e-01,\n",
       "         4.02148172e-01],\n",
       "       [-2.34014373e-02,  5.34318612e-02,  1.00912559e-03,\n",
       "         6.86493676e-02, -3.04421045e-01,  4.10127997e-01,\n",
       "         8.62968342e-02, -6.54657650e-02, -3.43491877e-02,\n",
       "         8.43267919e-01],\n",
       "       [-2.11710915e-01, -1.90432258e-01,  3.12703738e-01,\n",
       "         4.73102988e-02, -8.74689775e-02,  2.15846137e-01,\n",
       "         4.08246288e-01, -1.04089973e-01, -8.41041863e-01,\n",
       "        -1.26305719e+00],\n",
       "       [-2.13337222e-01,  1.38587274e-01, -1.64383299e-01,\n",
       "        -5.07815940e-02, -1.36620743e-01, -2.93165793e-01,\n",
       "        -1.07393589e-01, -2.86696441e-01, -9.91412522e-02,\n",
       "        -4.05470078e-01],\n",
       "       [-2.26122894e-01, -1.99250802e-01,  9.99379410e-02,\n",
       "        -1.64164584e-02,  3.36748163e-01, -4.03108581e-01,\n",
       "         6.86902526e-01, -2.36135639e-01, -3.67656004e-01,\n",
       "        -3.82247131e-01],\n",
       "       [-2.78783392e-01,  3.23640608e-02, -9.02658650e-02,\n",
       "        -2.86719172e-01, -1.47409103e-01,  1.78642771e-01,\n",
       "         3.09798266e-01,  1.42714962e-01, -6.30101584e-03,\n",
       "         5.06569970e-01],\n",
       "       [-1.35074290e-01, -1.29947389e-01, -1.27169498e-02,\n",
       "         8.10548927e-02, -6.30771251e-02,  4.26170444e-02,\n",
       "         1.28884319e-01, -5.39381942e-01, -5.29509945e-01,\n",
       "        -2.46680739e-01],\n",
       "       [ 1.09434789e-01, -1.87362548e-01, -5.04918207e-01,\n",
       "        -2.98454667e-01, -5.06238968e-01, -2.01530302e-01,\n",
       "         3.93570735e-01,  4.22269233e-01, -3.41272783e-02,\n",
       "         4.38062354e-01],\n",
       "       [-9.49730360e-02, -2.22954492e-01,  2.19110100e-02,\n",
       "        -4.11842894e-01,  1.56355202e-01,  5.15576793e-01,\n",
       "         2.87423793e-01,  1.19388140e-01, -2.55816405e-01,\n",
       "        -8.53195240e-02],\n",
       "       [-2.00114163e-01,  9.32173236e-02,  1.80001587e-02,\n",
       "        -1.55948911e-01, -3.98031487e-01, -1.90107860e-01,\n",
       "        -1.37084286e-01, -4.21122808e-01,  2.36478191e-01,\n",
       "        -8.50547979e-01],\n",
       "       [-8.02238080e-02,  6.58189804e-02,  4.43286289e-02,\n",
       "        -1.69331726e-01, -1.68610194e-01, -5.22649569e-02,\n",
       "        -4.12054737e-02,  2.30897409e-01, -1.37650686e-02,\n",
       "        -3.06794777e-01],\n",
       "       [ 8.61420953e-02, -4.34235674e-02,  3.52076249e-01,\n",
       "        -1.98256869e-01,  1.43745064e-01,  4.05528332e-01,\n",
       "        -9.78994479e-02, -2.65277624e-02,  4.16231536e-01,\n",
       "         6.30252845e-01],\n",
       "       [ 2.35557806e-01,  9.06603975e-02, -3.88522358e-01,\n",
       "         4.96554382e-02,  1.85647854e-02,  1.60866874e-01,\n",
       "         1.05460693e-01, -9.17546797e-02,  2.02315180e-01,\n",
       "        -9.74798093e-01],\n",
       "       [ 2.24096425e-02, -2.85541520e-02, -1.57570434e-01,\n",
       "        -1.18773288e-01,  6.24641888e-02,  2.64653098e-02,\n",
       "        -8.61477205e-02, -5.39367376e-01,  9.26893060e-01,\n",
       "        -9.24200769e-01],\n",
       "       [-3.03978359e-02,  1.84432559e-01, -3.42722201e-01,\n",
       "         3.66347741e-02, -2.74969222e-02,  6.11602526e-02,\n",
       "         4.93513500e-01, -9.15382796e-02, -9.73399179e-02,\n",
       "         6.29373939e-01]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = train_data.shape[1]\n",
    "\n",
    "means = np.zeros((n_features, 10)) \n",
    "\n",
    "for class_label in range(10):  \n",
    "    class_filter = (train_labels == class_label)\n",
    "    class_data = train_data[class_filter]\n",
    "    \n",
    "    if len(class_data) > 0:\n",
    "        for feature_idx in range(n_features):\n",
    "            feature_values = class_data[:, feature_idx]\n",
    "            \n",
    "            mean = np.sum(feature_values) / len(feature_values)\n",
    "            means[feature_idx, class_label] = mean\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92e0ca79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.40029698e-01, 8.48898400e-01, 3.37131756e+00, 8.82971762e-01,\n",
       "        9.43538116e-01, 6.27571578e+00, 1.58442047e+00, 1.04387452e+00,\n",
       "        2.84284103e+00, 1.53163520e+00],\n",
       "       [1.57393718e+00, 9.04655566e-01, 1.27997976e+00, 1.44451874e+00,\n",
       "        1.68777217e+00, 9.30455546e-01, 3.61448640e+00, 1.56387343e+00,\n",
       "        1.07275443e+00, 2.74189181e+00],\n",
       "       [6.65609904e+00, 1.91023784e+00, 2.24843367e+00, 2.32601404e+01,\n",
       "        1.70084825e+00, 1.86988079e+00, 1.17136237e+01, 2.38070346e+00,\n",
       "        4.78750556e-01, 1.33059992e+00],\n",
       "       [1.77119102e+00, 2.57509508e+00, 2.64757712e+00, 1.47936302e+00,\n",
       "        3.23754639e+00, 1.33680911e+00, 2.25614232e+00, 2.22816339e+00,\n",
       "        2.19968966e+00, 1.05736578e+00],\n",
       "       [3.48665789e+00, 3.55338122e+00, 1.71981928e+00, 5.82085865e+00,\n",
       "        2.68534529e+00, 2.42022989e+00, 3.82201732e+00, 4.08869954e+00,\n",
       "        1.74179179e+00, 6.01651510e+00],\n",
       "       [6.89782579e-03, 6.97818916e-03, 1.14942105e-02, 1.05516420e-02,\n",
       "        6.03493737e-03, 9.65555254e-03, 4.97525582e-03, 1.56486239e-02,\n",
       "        6.10196762e-03, 3.44787074e-04],\n",
       "       [1.10509088e+04, 1.01850271e+04, 7.00130321e+03, 8.78125978e+03,\n",
       "        5.98199570e+03, 6.76075188e+03, 6.69960355e+03, 1.05280703e+04,\n",
       "        1.55355486e+04, 3.83113675e+03],\n",
       "       [2.83043242e+07, 1.61233410e+07, 1.93811020e+07, 3.25761562e+07,\n",
       "        2.65822353e+07, 3.73568646e+07, 1.56217129e+07, 5.23202883e+06,\n",
       "        1.86673271e+06, 4.93409563e+06],\n",
       "       [2.71610325e+00, 3.34349123e+00, 3.23736690e+00, 3.07943804e+00,\n",
       "        3.50149041e+00, 3.82548337e+00, 5.09289564e+00, 3.49539694e+00,\n",
       "        1.03187978e+00, 1.45990771e+00],\n",
       "       [3.63914602e+00, 5.30831755e+00, 4.86486016e+00, 3.50101597e+00,\n",
       "        2.43238083e+00, 3.85633518e+00, 3.59070094e+00, 2.71512212e+00,\n",
       "        8.92346208e-01, 5.11238315e+00],\n",
       "       [2.63422392e+00, 3.36528372e+00, 5.82594784e+00, 3.82040472e+00,\n",
       "        2.62836170e+00, 3.03728739e+00, 1.94865685e+00, 2.48451309e+00,\n",
       "        2.94277091e+00, 3.01508392e+00],\n",
       "       [7.88614008e+00, 1.06394012e+01, 5.72147709e+00, 6.81608097e+00,\n",
       "        1.01568081e+01, 9.66343228e+00, 1.33576424e+01, 1.16102113e+01,\n",
       "        4.29840980e+00, 8.73234214e+00],\n",
       "       [1.38590037e+01, 1.66170471e+01, 1.59795259e+01, 1.77518927e+01,\n",
       "        1.90725210e+01, 9.99124354e+00, 7.36873160e+00, 1.14777033e+01,\n",
       "        1.54963438e+01, 9.84750555e+00],\n",
       "       [5.69900392e+01, 3.61802372e+01, 4.64155583e+01, 4.74337021e+01,\n",
       "        5.80995457e+01, 3.81403196e+01, 4.30058969e+00, 5.44618041e+01,\n",
       "        4.34364218e+01, 6.52835187e+01],\n",
       "       [4.84768704e+01, 2.77259080e+01, 3.75240489e+01, 4.59394218e+01,\n",
       "        4.49819924e+01, 3.50878537e+01, 4.24753229e+01, 6.27506972e+01,\n",
       "        3.35637235e+01, 4.64942058e+01],\n",
       "       [1.28417411e+01, 1.24651687e+01, 1.00993224e+01, 1.06082547e+01,\n",
       "        7.32438736e+00, 1.35165898e+01, 1.15695473e+01, 1.13741912e+01,\n",
       "        1.09112079e+01, 9.52678193e+00],\n",
       "       [1.09712866e+00, 9.93878677e-01, 7.58086270e-01, 1.12696482e+00,\n",
       "        8.17842766e-01, 1.26681058e+00, 1.72451755e+00, 9.15955266e-01,\n",
       "        7.08308612e-01, 4.44884809e-01],\n",
       "       [9.78505334e-01, 6.97238491e-01, 6.06185278e-01, 8.39773908e-01,\n",
       "        1.31752866e+00, 1.88990854e+00, 1.60958509e+00, 1.23010086e+00,\n",
       "        8.66413893e-01, 1.83055547e-01],\n",
       "       [1.52810621e+00, 6.87703553e-01, 1.79563962e+00, 1.49038860e+00,\n",
       "        7.04995877e-01, 5.31609679e-01, 6.53732930e-01, 9.24578066e-01,\n",
       "        1.22408452e+00, 1.25233684e-01],\n",
       "       [9.25235743e-01, 7.13246679e-01, 1.82885527e+00, 9.65734453e-01,\n",
       "        6.77991080e-01, 7.60345009e-01, 5.96669299e-01, 1.66142871e-01,\n",
       "        7.39566690e-01, 1.05721556e+00],\n",
       "       [7.94300981e-01, 9.34989856e-01, 9.07480972e-01, 1.11192888e+00,\n",
       "        1.05597430e+00, 2.91302963e-01, 2.65409402e-01, 9.58809160e-01,\n",
       "        3.92290011e-01, 8.13074800e-01],\n",
       "       [8.67218514e-01, 5.56170072e-01, 1.24371831e+00, 1.29109373e+00,\n",
       "        5.49546294e-01, 1.18446411e+00, 7.34448299e-01, 1.08389663e+00,\n",
       "        5.51514645e-01, 1.58281650e+00],\n",
       "       [1.29684908e+00, 5.30355124e-01, 1.16963434e+00, 8.09641295e-01,\n",
       "        6.54113757e-01, 5.62012475e-01, 1.09019842e+00, 1.27372646e+00,\n",
       "        7.33725839e-01, 6.41189037e-02],\n",
       "       [7.95050258e-01, 1.04568215e+00, 1.17843002e+00, 8.27549412e-01,\n",
       "        1.07630746e+00, 1.09580556e+00, 2.07145169e-01, 8.70625829e-01,\n",
       "        6.39752067e-01, 7.09228017e-02],\n",
       "       [9.79063009e-01, 1.15884673e+00, 7.12558238e-01, 6.66142694e-01,\n",
       "        5.84942638e-01, 1.00302855e+00, 1.22808858e+00, 1.68960560e+00,\n",
       "        1.52594765e+00, 1.94410720e-02],\n",
       "       [7.36744424e-01, 1.13773783e+00, 8.68377378e-01, 9.07030870e-01,\n",
       "        9.20324306e-01, 7.38796344e-01, 5.76851099e-01, 1.78131500e+00,\n",
       "        1.18385861e+00, 1.25081797e+00],\n",
       "       [9.25251731e-01, 9.67818196e-01, 8.27233644e-01, 9.85902185e-01,\n",
       "        1.14458160e+00, 1.10269263e+00, 9.16665482e-01, 8.51209571e-01,\n",
       "        1.35668766e+00, 9.71720792e-02],\n",
       "       [9.55656343e-01, 1.25306620e+00, 1.04492889e+00, 1.12132490e+00,\n",
       "        9.95799998e-01, 7.84030391e-01, 6.62705321e-01, 9.07026256e-01,\n",
       "        7.27610273e-01, 7.47783996e-01],\n",
       "       [8.52848562e-01, 9.50021944e-01, 8.57970354e-01, 1.12131593e+00,\n",
       "        1.27914187e+00, 4.12151332e-01, 7.99037451e-01, 1.35245820e+00,\n",
       "        9.88516042e-01, 3.09301252e+00],\n",
       "       [1.30562799e+00, 5.88795046e-01, 8.75027337e-01, 1.44626372e+00,\n",
       "        7.57755060e-01, 1.47944013e+00, 4.20659562e-01, 8.73545793e-01,\n",
       "        2.38822712e-01, 5.46879101e-02],\n",
       "       [8.75420268e-01, 9.69145926e-01, 9.72597146e-01, 8.26029227e-01,\n",
       "        1.33572891e+00, 6.32938465e-01, 1.33705478e+00, 1.09293381e+00,\n",
       "        7.54237947e-01, 2.46624973e-01],\n",
       "       [9.02550294e-01, 9.85071392e-01, 8.00942775e-01, 9.69923502e-01,\n",
       "        1.00273590e+00, 7.94444636e-01, 3.34399336e-01, 8.81665144e-01,\n",
       "        1.01398583e+00, 8.00237522e-01],\n",
       "       [7.79485287e-01, 1.00507182e+00, 9.12959785e-01, 1.40420376e+00,\n",
       "        5.84242742e-01, 2.37056941e+00, 7.57620592e-01, 6.62131751e-01,\n",
       "        1.12738281e+00, 1.78904053e-02],\n",
       "       [1.23608927e+00, 7.44895895e-01, 8.08014539e-01, 1.03631677e+00,\n",
       "        1.11181032e+00, 9.46776408e-01, 9.87431833e-01, 8.86890920e-01,\n",
       "        8.34700094e-01, 8.36386416e-01],\n",
       "       [8.50091555e-01, 6.72244402e-01, 9.50637401e-01, 6.39256287e-01,\n",
       "        9.24218955e-01, 5.53671311e-01, 2.71975223e-01, 5.90089102e-01,\n",
       "        1.13191640e+00, 1.46696038e+00],\n",
       "       [8.03903779e-01, 1.04725672e+00, 1.46928068e+00, 1.42157219e+00,\n",
       "        1.06522432e+00, 8.21920935e-01, 1.36316903e+00, 8.13554733e-01,\n",
       "        1.06049742e+00, 1.14706429e+00],\n",
       "       [1.22405781e+00, 7.75261238e-01, 1.40453385e+00, 6.10348849e-01,\n",
       "        6.61315738e-01, 1.19426041e+00, 5.78202655e-01, 6.41467457e-01,\n",
       "        3.71893520e-01, 6.58914110e-02],\n",
       "       [9.25932175e-01, 7.22210741e-01, 1.16232666e+00, 1.24797908e+00,\n",
       "        1.32171630e+00, 7.23175742e-01, 5.24401175e-01, 1.70956663e+00,\n",
       "        5.86540533e-01, 1.24333119e+00],\n",
       "       [1.12345133e+00, 6.59688656e-01, 1.01028078e+00, 5.53795310e-01,\n",
       "        1.75209200e+00, 9.90564223e-01, 1.13971393e+00, 1.03332498e+00,\n",
       "        1.64107481e+00, 9.46259727e-02],\n",
       "       [8.18231532e-01, 5.99789503e-01, 6.94562353e-01, 1.31045970e+00,\n",
       "        7.05752712e-01, 1.39511296e+00, 5.36401780e-01, 4.41078603e-01,\n",
       "        2.96635818e-01, 4.13648451e-02],\n",
       "       [6.05745269e-01, 1.13418540e+00, 1.32053983e+00, 8.32236250e-01,\n",
       "        1.01904696e+00, 1.21388003e+00, 1.35450044e-01, 1.02293123e+00,\n",
       "        4.19107007e-01, 2.61509228e-01],\n",
       "       [9.80993201e-01, 1.21686047e+00, 6.24085441e-01, 1.70444180e+00,\n",
       "        8.50386913e-01, 6.37004992e-01, 8.55074197e-01, 1.05096487e+00,\n",
       "        1.00364283e-01, 8.95251837e-02],\n",
       "       [1.14215330e+00, 5.53095248e-01, 1.32099332e+00, 1.33897749e+00,\n",
       "        6.77841429e-01, 9.82858678e-01, 6.61524817e-01, 6.78402422e-01,\n",
       "        1.31879968e+00, 6.83432760e-03],\n",
       "       [1.01951751e+00, 9.13223925e-01, 9.99527550e-01, 1.41989850e+00,\n",
       "        9.58211795e-01, 2.33743833e-01, 1.54555734e+00, 8.66421676e-01,\n",
       "        1.07254364e+00, 2.12395625e-02],\n",
       "       [1.04509139e+00, 1.01177449e+00, 9.63759889e-01, 8.72387754e-01,\n",
       "        8.79896352e-01, 1.49362291e+00, 4.64645786e-01, 1.21025034e+00,\n",
       "        1.17118425e+00, 7.03779031e-01],\n",
       "       [9.08818378e-01, 1.28390146e+00, 9.46581689e-01, 1.19787725e+00,\n",
       "        4.73975502e-01, 6.59121543e-01, 1.18421410e+00, 7.85356503e-01,\n",
       "        2.93239283e-01, 1.94996279e+00]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = train_data.shape[1]\n",
    "variances = np.zeros((n_features, 10))\n",
    "\n",
    "for class_label in range(10): \n",
    "    class_mask = (train_labels == class_label)\n",
    "    class_data = train_data[class_mask]\n",
    "    \n",
    "    if len(class_data) > 0:\n",
    "        for feature_idx in range(n_features):\n",
    "            feature_values = class_data[:, feature_idx]\n",
    "            \n",
    "            class_mean = means[feature_idx, class_label]\n",
    "            variance = np.sum((feature_values - class_mean) ** 2) / len(feature_values)\n",
    "            variances[feature_idx, class_label] = variance + 1e-9\n",
    "variances          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b969ffa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(x_0=-0.9785|c=0) = 1.619820e-01\n",
      "P(x_0=-0.9785|c=1) = 5.352380e-02\n"
     ]
    }
   ],
   "source": [
    "def class_conditional_fn(feature, class_label, mean, var):\n",
    "    coefficient = 1.0 / np.sqrt(2 * np.pi * var)\n",
    "    exponent = -((feature - mean) ** 2) / (2 * var)\n",
    "    cond_prob = coefficient * np.exp(exponent)\n",
    "    \n",
    "    return cond_prob\n",
    "\n",
    "tmp_feature = train_data[0, 0] \n",
    "print(f\"P(x_0={tmp_feature:.4f}|c=0) = {class_conditional_fn(tmp_feature, 0, means[0, 0], variances[0, 0]):.6e}\")\n",
    "print(f\"P(x_0={tmp_feature:.4f}|c=1) = {class_conditional_fn(tmp_feature, 1, means[0, 1], variances[0, 1]):.6e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef0e1b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(c=0 | x=[ 1.36163603e+00  1.84382833e+00  3.02578573e+00  6.25495590e+00\n",
      "  5.13827940e+00  9.86501644e-02 -1.53357002e+02  5.42097032e+04\n",
      "  6.11324699e-02 -8.10820015e-01  2.12975348e+00  2.24328804e-01\n",
      " -5.84441120e+00 -7.48194030e+00 -8.50218903e+00  7.34241152e+00\n",
      " -1.51295677e+00  3.10858191e-01 -1.57867520e+00 -2.12501365e-01\n",
      "  1.17894840e+00  5.96758646e-01 -2.02365398e+00  2.00451504e-01\n",
      " -3.19169915e-01 -1.27371740e+00  3.35021296e-01 -4.91737849e-01\n",
      " -4.85534039e-01  1.24045118e-01 -6.25884531e-01  9.57358339e-02\n",
      " -5.93324890e-01 -5.38461461e-01  9.92929769e-01  1.09467164e+00\n",
      " -1.70865425e+00  7.47072844e-01  1.39859100e+00  1.55737682e+00\n",
      "  5.20379726e-01 -1.05739786e+00  6.29980840e-01 -8.69252355e-01\n",
      " -3.42965166e-01  3.83082157e-01]) = 2.8532169387979976e-29\n",
      "P(c=1 | x=[ 1.36163603e+00  1.84382833e+00  3.02578573e+00  6.25495590e+00\n",
      "  5.13827940e+00  9.86501644e-02 -1.53357002e+02  5.42097032e+04\n",
      "  6.11324699e-02 -8.10820015e-01  2.12975348e+00  2.24328804e-01\n",
      " -5.84441120e+00 -7.48194030e+00 -8.50218903e+00  7.34241152e+00\n",
      " -1.51295677e+00  3.10858191e-01 -1.57867520e+00 -2.12501365e-01\n",
      "  1.17894840e+00  5.96758646e-01 -2.02365398e+00  2.00451504e-01\n",
      " -3.19169915e-01 -1.27371740e+00  3.35021296e-01 -4.91737849e-01\n",
      " -4.85534039e-01  1.24045118e-01 -6.25884531e-01  9.57358339e-02\n",
      " -5.93324890e-01 -5.38461461e-01  9.92929769e-01  1.09467164e+00\n",
      " -1.70865425e+00  7.47072844e-01  1.39859100e+00  1.55737682e+00\n",
      "  5.20379726e-01 -1.05739786e+00  6.29980840e-01 -8.69252355e-01\n",
      " -3.42965166e-01  3.83082157e-01]) = 3.2298580303391453e-28\n"
     ]
    }
   ],
   "source": [
    "def calc_posterior(class_label, feature):\n",
    "    likelihood = 1.0\n",
    "    \n",
    "    for feature_idx in range(len(feature)):\n",
    "        mean = means[feature_idx, class_label]\n",
    "        var = variances[feature_idx, class_label]\n",
    "        \n",
    "        feature_likelihood = class_conditional_fn(feature[feature_idx], class_label, mean, var)\n",
    "        likelihood *= feature_likelihood\n",
    "    \n",
    "    numerator = likelihood * priors[class_label]\n",
    "    denominator = 0.0\n",
    "    for c in range(10):  \n",
    "        class_likelihood = 1.0\n",
    "        for f_idx in range(len(feature)):\n",
    "            mean_c = means[f_idx, c]\n",
    "            var_c = variances[f_idx, c]\n",
    "            class_likelihood *= class_conditional_fn(feature[f_idx], c, mean_c, var_c)\n",
    "        denominator += class_likelihood * priors[c]\n",
    "    \n",
    "    post_prob = numerator / (denominator + 1e-10) \n",
    "    \n",
    "    return post_prob\n",
    "\n",
    "print(f\"P(c=0 | x={test_data[0]}) = {calc_posterior(0, test_data[0])}\")\n",
    "print(f\"P(c=1 | x={test_data[0]}) = {calc_posterior(1, test_data[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9bbea188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred class for x=[ 1.36163603e+00  1.84382833e+00  3.02578573e+00  6.25495590e+00\n",
      "  5.13827940e+00  9.86501644e-02 -1.53357002e+02  5.42097032e+04\n",
      "  6.11324699e-02 -8.10820015e-01  2.12975348e+00  2.24328804e-01\n",
      " -5.84441120e+00 -7.48194030e+00 -8.50218903e+00  7.34241152e+00\n",
      " -1.51295677e+00  3.10858191e-01 -1.57867520e+00 -2.12501365e-01\n",
      "  1.17894840e+00  5.96758646e-01 -2.02365398e+00  2.00451504e-01\n",
      " -3.19169915e-01 -1.27371740e+00  3.35021296e-01 -4.91737849e-01\n",
      " -4.85534039e-01  1.24045118e-01 -6.25884531e-01  9.57358339e-02\n",
      " -5.93324890e-01 -5.38461461e-01  9.92929769e-01  1.09467164e+00\n",
      " -1.70865425e+00  7.47072844e-01  1.39859100e+00  1.55737682e+00\n",
      "  5.20379726e-01 -1.05739786e+00  6.29980840e-01 -8.69252355e-01\n",
      " -3.42965166e-01  3.83082157e-01] = 1\n"
     ]
    }
   ],
   "source": [
    "def infer_class(feature):\n",
    "    best_class = 0\n",
    "    best_probability = 0.0\n",
    "    \n",
    "    for class_label in range(10):\n",
    "        posterior_prob = calc_posterior(class_label, feature)\n",
    "        if posterior_prob > best_probability:\n",
    "            best_probability = posterior_prob\n",
    "            best_class = class_label\n",
    "    \n",
    "    c = best_class\n",
    "    return c\n",
    "\n",
    "print(f\"Inferred class for x={test_data[0]} = {infer_class(test_data[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e87e2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  9.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  3.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  5.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  2.,  4.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "confusion_matrix = np.zeros((10, 10))\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(test_data)):\n",
    "    pred = infer_class(test_data[i])\n",
    "    predictions.append(pred)\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    true_label = int(test_labels[i])\n",
    "    pred_label = int(predictions[i])\n",
    "    confusion_matrix[true_label, pred_label] += 1\n",
    "\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3745695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7647\n",
      "Accuracy percentage: 76.47%\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = np.trace(confusion_matrix)  \n",
    "total_predictions = np.sum(confusion_matrix)     \n",
    "\n",
    "acc = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Accuracy percentage: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c875f40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7647 (76.47%)\n",
      "F1 Score (Macro): 0.5345\n",
      "F1 Score (Weighted): 0.7676\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.88      1.00      0.93         7\n",
      "           3       0.75      0.60      0.67         5\n",
      "           4       0.50      0.50      0.50         2\n",
      "           5       0.71      0.83      0.77         6\n",
      "           6       0.80      0.57      0.67         7\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.54      0.53      0.53        51\n",
      "weighted avg       0.78      0.76      0.77        51\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\busis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\busis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\busis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\busis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\busis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\busis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate F1 scores\n",
    "# Macro F1 (average of all classes)\n",
    "f1_macro = f1_score(test_labels, predictions, average='macro')\n",
    "\n",
    "# Weighted F1 (accounts for class imbalance)\n",
    "f1_weighted = f1_score(test_labels, predictions, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f} ({acc * 100:.2f}%)\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35a21cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (251, 47)\n",
      "Training labels shape: (251, 1)\n",
      "0        float64\n",
      "1        float64\n",
      "2        float64\n",
      "3        float64\n",
      "4        float64\n",
      "5        float64\n",
      "6        float64\n",
      "7        float64\n",
      "8        float64\n",
      "9        float64\n",
      "10       float64\n",
      "11       float64\n",
      "12       float64\n",
      "13       float64\n",
      "14       float64\n",
      "15       float64\n",
      "16       float64\n",
      "17       float64\n",
      "18       float64\n",
      "19       float64\n",
      "20       float64\n",
      "21       float64\n",
      "22       float64\n",
      "23       float64\n",
      "24       float64\n",
      "25       float64\n",
      "26       float64\n",
      "27       float64\n",
      "28       float64\n",
      "29       float64\n",
      "30       float64\n",
      "31       float64\n",
      "32       float64\n",
      "33       float64\n",
      "34       float64\n",
      "35       float64\n",
      "36       float64\n",
      "37       float64\n",
      "38       float64\n",
      "39       float64\n",
      "40       float64\n",
      "41       float64\n",
      "42       float64\n",
      "43       float64\n",
      "44       float64\n",
      "45       float64\n",
      "46        object\n",
      "label      int64\n",
      "dtype: object\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "5        0\n",
      "6        0\n",
      "7        0\n",
      "8        0\n",
      "9        0\n",
      "10       0\n",
      "11       0\n",
      "12       0\n",
      "13       0\n",
      "14       0\n",
      "15       0\n",
      "16       0\n",
      "17       0\n",
      "18       0\n",
      "19       0\n",
      "20       0\n",
      "21       0\n",
      "22       0\n",
      "23       0\n",
      "24       0\n",
      "25       0\n",
      "26       0\n",
      "27       0\n",
      "28       0\n",
      "29       0\n",
      "30       0\n",
      "31       0\n",
      "32       0\n",
      "33       0\n",
      "34       0\n",
      "35       0\n",
      "36       0\n",
      "37       0\n",
      "38       0\n",
      "39       0\n",
      "40       0\n",
      "41       0\n",
      "42       0\n",
      "43       0\n",
      "44       0\n",
      "45       0\n",
      "46       0\n",
      "label    0\n",
      "dtype: int64\n",
      "[0 2 7 6 1 3 8 5 4 9]\n",
      "F1 score using ONLY text column: 0.06398699723547088\n",
      "(251, 47)\n",
      "(251, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\busis\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load training features\n",
    "X_train = pd.read_csv(\"traindata.txt\", header=None, sep=',')\n",
    "\n",
    "# Load training labels\n",
    "y_train = pd.read_csv(\"trainlabels.txt\", header=None, names=['label'])\n",
    "\n",
    "# Display shapes to verify\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "\n",
    "X_train.head()\n",
    "\n",
    "y_train.head()\n",
    "\n",
    "#combining training data and training labels to make it easy to clean\n",
    "df = X_train.copy()\n",
    "df[\"label\"] = y_train.values.ravel() \n",
    "df.head()\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "#Checking if we have missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#dropping missing values\n",
    "columns_with_missing = [1, 5, 6, 7, 8, 14, 15, 17, 27, 34, 40]\n",
    "\n",
    "for col in columns_with_missing:\n",
    "    df[columns_with_missing] = df[columns_with_missing].fillna(df[columns_with_missing].median())\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(df['label'].unique())\n",
    "\n",
    "texts = df.iloc[:, 46].astype(str)   # Column with random words\n",
    "labels = df.iloc[:, 47].astype(int)  # Labels from 0 to 9\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # Limit for speed\n",
    "X_text = vectorizer.fit_transform(texts)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "scores = cross_val_score(clf, X_text, labels, scoring='f1_macro', cv=5)\n",
    "\n",
    "print(\"F1 score using ONLY text column:\", scores.mean())\n",
    "\n",
    "##drop 46 as it has not much predictive power on label\n",
    "df = df.drop(columns=df.columns[46])\n",
    "\n",
    "df.head()\n",
    "\n",
    "##feature selection based on correlations, dropping features that have low correlation and keepting top 20\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1].astype(int) \n",
    "\n",
    "\n",
    "correlations = features.corrwith(labels).abs().sort_values(ascending=False)\n",
    "top_n = 20\n",
    "top_features = correlations.head(top_n).index\n",
    "\n",
    "\n",
    "X_selected = features[top_features]\n",
    "\n",
    "\n",
    "df_selected = pd.concat([X_selected, labels], axis=1)\n",
    "\n",
    "\n",
    "df_selected.head()\n",
    "\n",
    "#new preprocessed datset must have same number of rows as old dataset but less columns due to feature selection\n",
    "print(df.shape)\n",
    "print(df_selected.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
